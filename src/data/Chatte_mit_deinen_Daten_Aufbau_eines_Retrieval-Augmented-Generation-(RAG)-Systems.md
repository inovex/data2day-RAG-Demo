# Chatte mit deinen Daten: Aufbau eines Retrieval-Augmented-
Generation-(RAG)-Systems
In diesem Workshop werden die Teilnehmer dazu befähigt, ein Retrieval-
Augmented-Generation-System (RAG) zu entwickeln, das Anfragen gegen eine
umfangreiche Textdatenbank bearbeitet.  
  
Durch den Aufbau eines Embeddings-basierten Index und die kontextbasierte
Beantwortung von Fragen anhand relevanter Dokumente lernen die
Teilnehmer:innen, wie sie ihre Daten in eine interaktive Konversation
verwandeln können.
## Vorkenntnisse
Die Zielgruppe für diesen Workshop sind Entwickler, die entweder noch keine
oder nur geringe praktische Erfahrung mit Large Language Models (LLMs) haben
und über grundlegende Python-Kenntnisse verfügen.
## Lernziele
  1. Daten für und mit Large Language Models (LLMs) aufarbeiten und persistieren: Die Teilnehmer werden lernen, wie man Daten für die Verarbeitung mit LLMs vorbereitet und wie man sie effektiv persistiert, um den Trainingsprozess zu unterstützen.  
  2. Verarbeitung von (Text)daten mit LLMs: Die Teilnehmer werden die Grundlagen der Verarbeitung von Textdaten mit LLMs kennenlernen. Dies umfasst das Einlesen, Vorbereiten und Anwenden von LLMs auf Textdaten.  
  3. Erfahrungen mit Large Language Models sammeln: Durch praktische Übungen und Beispiele werden die Teilnehmer Erfahrungen im Umgang mit LLMs sammeln, um ein besseres Verständnis für deren Funktionsweise und Anwendungsmöglichkeiten zu entwickeln.
## Agenda
  * ab 09:00 Uhr: Registrierung und Begrüßungskaffee 
  * 10:00 Uhr: Beginn 
  * Vorstellung RAG System 
  * Präsentation RAG Komponenten 
    * Streamlit UI 
    * Langchain Backend 
      * Azure OpenAI 
      * Prompting 
      * Agents 
      * Multimodal
  * Setup RAG Umgebung 
  * Setup künstliche Firmendatenbank 
  * 12:30 - 13:30 Uhr: Mittagspause 
  * Implementieren eines RAG Prototypen mit den vorgestellten Komponenten 
  * Dazwischen: Kaffeepausen um 15:00 Uhr und um 16:15 Uhr 
  * ab 16:30: Test RAG Prototyp 
  * ca. 17:00 Uhr: Ende
## Technische Anforderungen
Bringt einen eigenen Laptop mit, der über mindestens 100 MB freien
Festplattenspeicher (für Testdaten und Testdatenbank) verfügt.  
  
Installiert vor dem Workshop eine Python-Umgebung (3.11) und erstellt eine
virtuelle Umgebung (<https://python.land/virtual-environments/virtualenv>).
Sie ist für alle Plattformen verfügbar.  
Ladet gerne bereits ein Setup Github Repository. Der Link wird vor dem
Workshop verschickt.  
  
Falls ihr ein Gerät eurer Firma verwendet, überprüft vorher bitte, ob eines
der folgenden, gelegentlich vorkommenden Probleme bei euch auftreten könnte.  
  * Workshop-Teilnehmer:in hat keine Administrator-Rechte.  
  * Corporate Laptops mit übermäßig penibler Sicherheitssoftware  
  * Gesetzte Corporate-Proxies, über die man in der Firma kommunizieren muss, die aber in einer anderen Umgebung entsprechend nicht erreicht werden.
## Speaker
![Fabian Kaiser](/common/images/numbers/22538_1.jpg)  
**Fabian Kaiser** ist Experte für Generative AI. Er hat nach seinem Master in
Informatik mit Fokus auf Natural Language Processing (NLP) ein Jahr lang am
Ubiquitous Knowledge Processing (UKP) Lab zu Argument Mining in juristischen
Texten geforscht. Seitdem hat er an diversen Projekten mit Fokus auf
Textverarbeitung, IoT und Cloud Computing gearbeitet.
[Jetzt Tickets sichern](https://data2day.de/tickets.php)