# Der Mensch im Fokus: nutzerzentriert, vertrauenswürdige KI-Technologie
entwickeln
Leistungsstarke KI-Technologie gleicht häufig einer Blackbox, und das "Warum?"
hinter ihren Entscheidungsprozessen einem Mysterium, selbst für ihre
Entwickler:innen. Das stellt die Vertrauenswürdigkeit von KI-Systemen infrage.  
  
Explainable AI (XAI) findet Antworten – primär in algorithmischen Methoden,
die komplexe Entscheidungsprozesse von KI-Systemen für Menschen verständlich
machen. Die Richtung stimmt, beleuchtet das Problem aber nur eindimensional,
denn Ihre Effektivität hängt ebenso davon ab, wie gut nicht-technische
Nutzergruppen die Erklärungen verstehen.  
  
Human-Centered Explainable AI stellt Endanwender:innen ins Zentrum der KI-
Entwicklung. In interaktiven User Interfaces werden XAI-Methoden visualisiert
und es den Nutzer:innen so ermöglicht, auf explorative Weise mit den KI-
Modellen zu interagieren, um Einblicke in ihre Funktionsweise zu gewinnen und
Vertrauen aufzubauen.  
  
Wie sieht das in der Praxis aus?  
  
Am Beispiel eines ML-basierten Nachfrageprognose-Systems führt der Vortrag
praxisnah durch die Wichtigkeit von User Research, die Selektion und
Visualisierung von XAI-Methoden in einem User Interface. Ziel ist es, das
Potenzial aufzuzeigen, KI-Entwicklung interdisziplinär zu denken, um
vertrauenswürdige Lösungen zu bauen, die menschliche Kompetenz nicht ersetzen,
sondern ergänzen.
## Vorkenntnisse
Vorkenntnisse in Machine Learning, Explainable AI und UI/UX Design werden für
das Verständnis des Vortrags nicht vorausgesetzt. Grundprinzipien, Design
Pattern und XAI-Methoden werden erläutert.
## Lernziele
Teilnehmende verstehen die Relevanz von Explainable AI in Kombination mit
einem menschenzentrierten Designprozess für die Entwicklung vertrauenswürdiger
KI-Systeme. Der Zusammenhang von Erklärungen als integraler Bestandteil
menschlicher Kognitionsprozesse und die Adaption auf XAI-Methoden wird
vermittelt, und Zuhörer:innen erkennen das Potenzial von interaktiven User
Interfaces für die effektive Gestaltung eines Mensch-KI-Dialogs.
## Speaker
![Alina Döring](/common/images/numbers/22245_1.jpg)  
**Alina Döring** ist UI/UX-Designerin bei inovex und studiert im Master
"Computer Science and Media". Der Schwerpunkt ihrer Forschung liegt auf der
Schnittstelle von User Experience Design und Machine Learning. Dabei
untersucht sie die Gestaltung von Human-AI-Interaction durch Human-centered
Explainable AI und integriert Erkenntnisse aus der Verhaltenspsychologie für
einen holistischen Designprozess.
![Robin Senge](/common/images/numbers/22245_2.jpg)  
**Robin Senge** ist Head of Machine Learning bei inovex. Er leitet ein Team
von Data Scientists und Data Engineers und konzipiert als Spezialist für
Maschinelles Lernen datengetriebene Use-Cases im Bereich Handel und Supply-
Chain. Dr. Senge forscht aktiv im Bereich der Sicherheit von KI-Systemen sowie
ihrer Interaktion mit dem Menschen durch Human-centered Explainable AI.
[Jetzt Tickets sichern](https://data2day.de/tickets.php)