# Die Engineering-Perspektive auf den EU AI Act
Trustworthy AI ist eine zentrale Motivation hinter dem EU AI Act. Dieser
gesetzliche Rahmen legt vielschichtige und anspruchsvolle Anforderungen an KI-
Systeme fest und kategorisiert sie in vier Risikogruppen: verbotene,
hochriskante, begrenzt riskante KI-Systeme und solche mit minimalem Risiko.  
  
Angesichts der Schonfrist von 6 bis 24 Monaten nach Veröffentlichung der
Verordnung wird empfohlen, dass Unternehmen, die KI einsetzen, mit der
Vorbereitung auf die zukünftigen Anforderungen beginnen. Um die technische
Bereitschaft für die Einhaltung des AI Act zu erreichen, ist es wesentlich,
etablierte Data-Governance, KI-Governance und MLOps-Techniken über die gesamte
Lebensdauer eines ML/AI-Systems anzuwenden.  
  
Dieser Vortrag zielt darauf ab, Entwickler und Data Science Teams mit einem
umfassenden Verständnis der Anforderungen des EU AI Act auszustatten. Er
bietet auch praktische Anleitungen zur Implementierung von MLOps und Data-
Governance-Prozessen, die der Verordnung entsprechen. Dieser Vortrag wird die
Ingenieursperspektive auf die proaktive Implementierung des EU AI Act geben.
## Vorkenntnisse
Erfahrung mit MLOps
## Lernziele
Nach dem Talk sind ML Engineers in der Lage, proaktiv konforme MLOps-Prozesse
und -Systeme zu entwerfen und zu implementieren und dabei die regulatorischen
Anforderungen effektiv zu meistern.
## Speaker
![Larysa Visengeriyeva](/common/images/numbers/22259_1.jpg)  
**Larysa Visengeriyeva** ist Technologieberaterin und Expertin für
Datenqualität, maschinelles Lernen und MLOps. Sie promovierte in Augmented
Data Quality Management an der TU Berlin. Bei INNOQ.AI ist sie Head of Data
and AI und arbeitet an der Operationalisierung von ML-Systemen und
Datenarchitekturen. Larysa gründete das Sommerfestival Women+ in Data and AI.
[ __@visenger](https://x.com/visenger)
[Jetzt Tickets sichern](https://data2day.de/tickets.php)